#!/usr/bin/env Rscript
library(optparse)
library(rstan)

#' Dirichlet multinomial GLM for confounder removal and PSI quantification
#'
#' @param x [samples] x [covariates] matrix of confounders
#' @param cluster_counts [samples] x [introns] matrix of intron usage counts
#' @param concShape Gamma shape parameter for concentration parameter
#' @param concRate Gamma rate parameter for concentration parameter
#' @param debug Whether to give verbose output from rstan.
#' @param init Can be one of {"smart", "random"}. smart uses an method of moments estimator to get a reasonable initialization. The seed for "random" can be set through the ... arguments passed to rstan::optimizing.
#' @param smart_init_regularizer Used to protect against colinear covariates. 
#' @param residual_sigma Std of regularization on residuals.
#' @param ... will be passed on the rstan::optimizing, so can be used for example to set the algorithm used (default is LBFGS) or the random seed if random initialization is requested. 
#' @importFrom rstan optimizing
#' @import foreach
#' @import dplyr
#' @import magrittr
#' @export
# Generated by rstantools.  Do not edit by hand.
library(magrittr)
library(dplyr)
# names of stan models
MODELS_HOME <- "/research/rgs01/home/clusterHome/yli11/.conda/envs/leafcutter_env8/lib/R/library/leafcutter/stan"
if (!file.exists(MODELS_HOME)) MODELS_HOME <- sub("R$", "exec", getwd())

stan_files <- dir(MODELS_HOME, pattern = "stan$", full.names = TRUE)
stanmodels <- sapply(stan_files, function(f) {
  model_cppname <- sub("\\.stan$", "", basename(f))
  isystem <- system.file("chunks", package = methods::getPackageName(environment(), FALSE))
  if (!file.exists(file.path(isystem, "common_functions.stan")))
    isystem <- file.path("inst", "chunks")
  if (!file.exists(file.path(isystem, "common_functions.stan")))
    isystem <- file.path("..", "inst", "chunks")
  stanfit <- rstan::stanc_builder(f, isystem)
  stanfit$model_cpp <- list(model_cppname = stanfit$model_name, 
                            model_cppcode = stanfit$cppcode)
  return(do.call(methods::new, args = c(stanfit[-(1:3)], Class = "stanmodel", 
                 mk_cppmodule = function(x) get(paste0("model_", model_cppname)))))
  }
)
names(stanmodels) <- sub("\\.stan$", "", basename(names(stanmodels)))
print (stanmodels)
quantify_psi_one_cluster <- function(cluster_counts,x,protected,concShape=1.0001,concRate=1e-4, debug=F, init_strategy="smart", smart_init_regularizer=0.001, residual_sigma=10, ...) {
  K=ncol(cluster_counts)
  
  model_to_use=stanmodels$dm_glm_multi_conc
  
  dat_null=list(N=nrow(x), K=K, P=ncol(x), y=cluster_counts, x=x, concShape=concShape,concRate=concRate)
  
  if (init_strategy=="smart") {
    y_norm = sweep(cluster_counts+1,1,rowSums(cluster_counts+1),"/") %>% log()
				# y_norm = log(sweep(cluster_counts + 1, 1, rowSums(cluster_counts + 1), "/"))
    beta_mm = solve( t(x) %*% x + smart_init_regularizer * diag(ncol(x)), t(x) %*% y_norm )
    beta_norm = sweep(beta_mm, 1, rowMeans(beta_mm), "-")
    beta_scale = foreach(i=seq_len(nrow(beta_norm)), .combine = c) %do% {
      beta_row = beta_norm[i,]
      up=beta_row[which.max(abs(beta_row))] / (1-1/K)
      down=beta_row[which.max(-sign(up)*beta_row)] / (1/K)
      up-down
    }
    beta_raw=sweep(beta_norm,1,beta_scale+1e-20,"/") + 1/K
    beta_raw=sweep(beta_raw,1,rowSums(beta_raw),"/")
    init=list(beta_scale=array(beta_scale), beta_raw=beta_raw, conc=rep(10.0,K))
  }
 ##model_to_use <- stanmodels$dm_glm_mc_psi
  fit=optimizing(model_to_use, data=dat_null, init=init, as_vector=F, verbose=debug, ...)

  dimnames(fit$par$beta_raw)=list(colnames(x),colnames(cluster_counts))
  
  dat_null$beta=t(beta_real(fit$par))
  dat_null$conc=fit$par$conc
  dat_null$residual_sigma=residual_sigma
  fit_psi=optimizing(stanmodels$dm_glm_mc_psi, data=dat_null, init=0, as_vector=F, verbose=debug, ...)
  normalize=function(g) { g/sum(g) }
  softmax=function(g) normalize(exp(g))
  
  lo_residuals = fit_psi$par$residual + x[,protected,drop=F] %*% t(dat_null$beta[,protected,drop=F])
  
  lo_residuals %>%
    apply( 1,softmax) %>% # implicit t() here
    sweep(1,fit$par$conc,"*") %>% 
    apply( 2,normalize) %>% 
    magrittr::set_rownames(colnames(cluster_counts)) %>%
    magrittr::set_colnames(rownames(cluster_counts))
}
library("foreach")
library("R.utils")
#' Confounder removal and PSI quantification
#'
#' @param counts An [introns] x [samples] matrix of counts. The rownames must be of the form chr:start:end:cluid. If the counts file comes from the leafcutter clustering code this should be the case already.
#' @param x A [samples] x [confounders] numeric matrix to be controlled for in the GLM. Factors should already have been converted to a 1-of-(K-1) encoding, e.g. using model.matrix (see scripts/leafcutter_ds.R for how to do this). 
#' @param protected Indices (boolean or integer) corresponding to which columns of x should be protected rather than regressed out. 
#' @param timeout Maximum time (in seconds) allowed for a single optimization run
#' @param debug If true writes more output
#' @param init One of 'smart' (default) or 'random'. If 'random' you can pass an additional arg "seed" for reproducibility. 
#' @return A per cluster list of results. Clusters that were not tested will be represented by a string saying why.
#' @import foreach
#' @importFrom R.utils withTimeout
#' @export
quantify_psi=function(counts, x, protected, timeout=10, debug=F, init="smart", ...) {
  
  introns=get_intron_meta(rownames(counts))
  cluster_ids=paste(introns$chr,introns$clu,sep = ":")
  
  cluster_sizes=as.data.frame(table(cluster_ids))
  clu_names=as.character(cluster_sizes$cluster_ids)
  
  if (!debug) {
    zz <- file( "/dev/null", open = "wt")
    sink(zz)
    sink(zz, type = "message")
  }
  
  tryCatch( {
  psi_matrix=do.call(rbind, foreach (cluster_name=clu_names, .errorhandling = if (debug) "stop" else "pass") %dopar% {
    cluster_counts=t(counts[ cluster_ids==cluster_name, ])
    withTimeout( { 
      quantify_psi_one_cluster(cluster_counts, x, protected, debug=debug, init=init,...)
    }, timeout=timeout, onTimeout=if (debug) "silent" else "warning" ) 
  } )
  }, error=function(g) {
    if (!debug) {
      sink(type="message")
      sink()
    }
    print(g)
    return(NULL)
  } )
  
  if (!debug) {
    sink(type="message")
    sink()
  }
  
  psi_matrix
}

arguments <- parse_args(OptionParser(usage = "%prog [options] counts_file", description="LeafCutter PSI quantification command line tool. Required inputs:\n <counts_file>: Intron usage counts file. Must be .txt or .txt.gz, output from clustering pipeline.\n <confounders_file>: ",option_list=list(
  make_option(c("-c","--confounders_file"), default=NULL, help="One+K column file: 1. sample names (must match column names in counts_file), 2. Additional columns are used to specify confounders, e.g. batch/sex/age. Numeric columns will be treated as continuous, so use e.g. batch1, batch2, batch3 rather than 1, 2, 3 if you want a categorical variable."),
  make_option(c("-o","--output_file"), default = "leafcutter_psi.txt.gz", help="The output file, will be gzipped [default %default]"),
   make_option(c("-t","--timeout"), default=10, help="Maximum time (in seconds) allowed for a single optimization run [default %default]"),
  make_option(c("-p","--num_threads"), default=1, help="Number of threads to use [default %default]"),
  make_option(c("--init"), default="smart", help="One of 'smart' (default) or 'random'."), 
  make_option(c("--seed"), default=12345, help="Random seed if using random initialization."))),
  positional_arguments = 1)

library(leafcutter)

opt=arguments$opt
counts_file=arguments$args[1]

cat("Loading counts from",counts_file,"\n")
if (!file.exists(counts_file)) stop("File ",counts_file," does not exist")
counts=read.table(counts_file, header=T, check.names = F)

if (!is.null(opt$confounders_file)) {
  cat("Loading counfounders from",opt$confounders_file,"\n")
  if (!file.exists(opt$confounders_file)) stop("File ",opt$confounders_file," does not exist")
  meta=read.table(opt$confounders_file, header=F, stringsAsFactors = F)
  colnames(meta)[1]="sample"
  counts=counts[,meta$sample]
  
  confounders=meta[,2:ncol(meta),drop=F]
  # scale continuous confounders
  for (i in seq_len(ncol(confounders)))
    if (is.numeric(confounders[,i]))
      confounders[,i]=scale(confounders[,i])
  # convert factors to one-of-K encoding
  confounders=model.matrix( ~., data=confounders )
  confounders=confounders[,2:ncol(confounders),drop=F] # remove intercept
  
} else {
  confounders = matrix(0,nrow=ncol(counts),ncol=0)
}

require(doMC)
registerDoMC(opt$num_threads)

cat("Settings:\n")
print(opt)

cat("Running PSI quantification\n")
x=cbind(intercept=1,confounders)
psi_matrix <- quantify_psi(counts, x, protected=1, timeout=opt$timeout, init=opt$init, seed=opt$seed , debug = T) 
print (head(psi_matrix))
stopifnot(!is.null(psi_matrix))

cat("Saving results...\n")
gz=gzfile(opt$output_file, "wb")
write.table(psi_matrix, gz, quote=F, sep="\t",col.names = T,row.names = T)
close(gz)

cat("All done, exiting\n")
